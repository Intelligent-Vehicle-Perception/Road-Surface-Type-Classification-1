{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Classical Methods - Processing.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"AfUY980oHz6l","colab_type":"text"},"source":["<h1>Classical Methods - Processing</h1>"]},{"cell_type":"markdown","metadata":{"id":"E0bktgnxHz6p","colab_type":"text"},"source":["<h5>Importing Packages</h5>"]},{"cell_type":"code","metadata":{"id":"YBcblDBrHz6q","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.stats import mode\n","from joblib import dump, load\n","from tqdm.notebook import tqdm\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.cluster import KMeans\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, plot_confusion_matrix, confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3mHY2GihHz6v","colab_type":"text"},"source":["<h5>Data Parameters</h5>"]},{"cell_type":"code","metadata":{"id":"coeV-vfdjjE-","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","# %matplotlib notebook\n","# pd.set_option(\"float_format\", '{:0.10f}'.format)\n","# pd.set_option('display.max_columns', 30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN18hT3nHz6x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1587240985866,"user_tz":180,"elapsed":10301,"user":{"displayName":"Jeferson Menegazzo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQawyEgOlmBHPaOoOT_loAbYF9XYcZK5PiYARmfg=s64","userId":"12080988616245410525"}},"outputId":"c2965d67-9ab0-4bfe-c333-b08f0565931f"},"source":["try:\n","    import google.colab\n","    datasets_folder = '/drive/My Drive/Colab Notebooks/DataSets/'\n","    work_folder = '/drive/My Drive/Colab Notebooks/Experiments/Classical Machine Learning/'\n","    IN_COLAB = True\n","except:\n","    datasets_folder = '/Google Drive/Colab Notebooks/DataSets/'\n","    work_folder = '/Google Drive/Colab Notebooks/Experiments/Classical Machine Learning/'\n","    IN_COLAB = False\n","\n","print(\"In Colab:\", IN_COLAB)\n","print(\"Work Folder:\", work_folder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["In Colab: True\n","Work Folder: /drive/My Drive/Colab Notebooks/Experimentos/Classical Machine Learning/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JFhlP_PnHz60","colab_type":"text"},"source":["<h5>Data Functions</h5>"]},{"cell_type":"code","metadata":{"id":"tcNAKBG_Hz61","colab_type":"code","colab":{}},"source":["# Load raw datasets from disk\n","# Input: folder where is the datasets folder and files\n","# Output: dict -> { \"pvs_x\": { \"left\": df, \"right\": df, \"labels\": df } }\n","def getDataSets(folder=datasets_folder):\n","    \n","    datasets = {}\n","    \n","    for i in range(1, 10):\n","        \n","        dataset_folder = os.path.join(folder, \"PVS \" + str(i))\n","        \n","        left =   pd.read_csv(os.path.join(dataset_folder, 'dataset_gps_mpu_left.csv'),  float_precision=\"high\")\n","        right =  pd.read_csv(os.path.join(dataset_folder, 'dataset_gps_mpu_right.csv'), float_precision=\"high\")\n","        labels = pd.read_csv(os.path.join(dataset_folder, 'dataset_labels.csv'),        float_precision=\"high\")\n","        \n","        datasets[\"pvs_\" + str(i)] = {\n","            \"left\": left,\n","            \"right\": right,\n","            \"labels\": labels\n","        }\n","    \n","    return datasets\n","\n","# Get fields filtering by inputs\n","# Input: data types and placements\n","# Output: string[]\n","def getFields(acc=False, gyro=False, mag=False, temp=False, speed=False, location=False, below_suspension=False, above_suspension=False, dashboard=False):\n","    \n","    all_fields = [\n","        'timestamp', \n","        'acc_x_dashboard', 'acc_y_dashboard', 'acc_z_dashboard',\n","        'acc_x_above_suspension', 'acc_y_above_suspension', 'acc_z_above_suspension', \n","        'acc_x_below_suspension', 'acc_y_below_suspension', 'acc_z_below_suspension', \n","        'gyro_x_dashboard', 'gyro_y_dashboard', 'gyro_z_dashboard', \n","        'gyro_x_above_suspension', 'gyro_y_above_suspension', 'gyro_z_above_suspension',\n","        'gyro_x_below_suspension', 'gyro_y_below_suspension', 'gyro_z_below_suspension', \n","        'mag_x_dashboard', 'mag_y_dashboard', 'mag_z_dashboard', \n","        'mag_x_above_suspension', 'mag_y_above_suspension', 'mag_z_above_suspension', \n","        'temp_dashboard', 'temp_above_suspension', 'temp_below_suspension', \n","        'timestamp_gps', 'latitude', 'longitude', 'speed'\n","    ]\n","    \n","    return_fields = []\n","    \n","    for field in all_fields:\n","            \n","        data_type = False\n","        placement = False\n","        \n","        if(speed and field == \"speed\"):\n","            placement = data_type = True\n","            \n","        if(location and (field == \"latitude\" or field == \"longitude\")):\n","            placement = data_type = True\n","        \n","        if(acc):\n","            data_type = data_type or field.startswith(\"acc_\")\n","        \n","        if(gyro):\n","            data_type = data_type or field.startswith(\"gyro_\")\n","            \n","        if(mag):\n","            data_type = data_type or field.startswith(\"mag_\")\n","            \n","        if(temp):\n","            data_type = data_type or field.startswith(\"temp_\")\n","            \n","        if(below_suspension):\n","            placement = placement or field.endswith(\"_below_suspension\")\n","            \n","        if(above_suspension):\n","            placement = placement or field.endswith(\"_above_suspension\")\n","            \n","        if(dashboard):\n","            placement = placement or field.endswith(\"_dashboard\")\n","        \n","        if(data_type and placement):\n","            return_fields.append(field)\n","            \n","    return return_fields\n","\n","# Get subsets from raw datasets. \n","# For each raw dataset, returns a subset with only fields passed.\n","# Input: raw datasets (dict), fields (string[]) and labels (string[])\n","# Output: dict -> { \"pvs_x\": { \"left\": df, \"right\": df, \"labels\": df } }\n","def getSubSets(datasets, fields, labels):\n","    \n","    subsets = {}\n","    \n","    for key in datasets.keys():\n","        \n","        subsets[key] = {\n","            \"left\": datasets[key][\"left\"][fields],\n","            \"right\": datasets[key][\"right\"][fields],\n","            \"labels\": datasets[key][\"labels\"][labels]\n","        }\n","    \n","    return subsets\n","\n","# Generate a dict with agg functions for all fields based on inputs\n","# Input: fields and arrays with agg functions to each data type.\n","# Output: dict -> { field: aggFn }\n","def getAggFunctions(fields, acc=None, gyro=None, mag=None, speed=None):\n","\n","    agg_fn = {}\n","\n","    for field in fields:\n","        \n","        if(field.startswith(\"acc_\")):\n","            agg_fn[field] = acc\n","        \n","        elif(field.startswith(\"gyro_\")):\n","            agg_fn[field] = gyro\n","        \n","        elif(field.startswith(\"mag_\")):\n","            agg_fn[field] = mag\n","        \n","        elif(field == \"speed\"):\n","            agg_fn[field] = speed\n","        \n","        else:\n","            agg_fn[field] = None\n","            \n","    return agg_fn\n","\n","# Extract features from subsets.\n","# Input: subsets, window function, window size, aggregation functions and sides.\n","# Output: dict -> { \"pvs_x\": { \"left\": { \"inputs\": df, \"outputs\": df }, \"right\": { \"inputs\": df, \"outputs\": df } } }\n","def getExtractedFeatures(subsets, window_fn, window, agg_fn, sides=['left', 'right']):\n","    \n","    feature_sets = {}\n","    \n","    for key in subsets.keys():\n","\n","        feature_sets[key] = {}\n","\n","        for side in sides:\n","    \n","            inputs, outputs = window_fn(subsets[key][side], subsets[key][\"labels\"], window, agg_fn)\n","            \n","            feature_sets[key][side] = {\n","                \"inputs\": inputs,\n","                \"outputs\": outputs\n","            }\n","\n","    return feature_sets\n","\n","# Get train and test sets from feature sets.\n","# Inputs: feature sets (dict), setsTrain (string[]) and setsTest(string[]) with datasets names (\"pvs_x\"), and sides.\n","# Outputs: df -> input train, input test, output train, output test\n","def getTrainTestSets(feature_sets, sets_train, sets_test, sides=['left', 'right']):\n","    \n","    input_train = pd.DataFrame()\n","    input_test = pd.DataFrame()\n","    output_train = pd.DataFrame()\n","    output_test = pd.DataFrame()\n","\n","    for key in feature_sets.keys():\n","\n","        for side in sides:\n","    \n","            if (key in sets_train):\n","                input_train  = input_train.append(feature_sets[key][side][\"inputs\"], ignore_index=True)\n","                output_train = output_train.append(feature_sets[key][side][\"outputs\"], ignore_index=True)\n","                \n","            elif (key in sets_test):\n","                input_test  = input_test.append(feature_sets[key][side][\"inputs\"],    ignore_index=True)\n","                output_test = output_test.append(feature_sets[key][side][\"outputs\"], ignore_index=True)\n","\n","    return input_train, input_test, output_train, output_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wgdwJd7SHz64","colab_type":"text"},"source":["<h5> Feature Extraction </h5>"]},{"cell_type":"code","metadata":{"id":"dNpgnINhHz65","colab_type":"code","colab":{}},"source":["# Moving Window\n","def extractFeatureMovingWindow(data, labels, window, agg_fn):\n","    \n","    if(window == 1):\n","        return data, labels\n","    \n","    inputs = data.rolling(window).agg(agg_fn)\n","    outputs = labels.rolling(window).mean().round(0)\n","    \n","    inputs.columns = ['_'.join(col_in).strip() for col_in in inputs.columns.values]\n","    \n","    inputs = inputs[window-1:]\n","    outputs = outputs[window-1:]\n","    \n","    inputs = inputs.reset_index(drop=True)\n","    outputs = outputs.reset_index(drop=True)\n","    \n","    return inputs, outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"watwtvcfHz68","colab_type":"code","colab":{}},"source":["# Fixed Window\n","def extractFeatureFixedWindow(data, labels, window, agg_fn):\n","    \n","    if(window == 1):\n","        return data, labels\n","    \n","    inputs, outputs = extractFeatureMovingWindow(data, labels, window, agg_fn)\n","    select_index = np.arange(0, len(inputs), window)\n","\n","    inputs = inputs.iloc[select_index, :]\n","    outputs = outputs.iloc[select_index, :]\n","    \n","    inputs = inputs.reset_index(drop=True)\n","    outputs = outputs.reset_index(drop=True)\n","    \n","    return inputs, outputs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ty4-wUNHz7B","colab_type":"text"},"source":["<h5>Dump and Load Models</h5>"]},{"cell_type":"code","metadata":{"id":"UNr0KnHdHz7C","colab_type":"code","colab":{}},"source":["# Model - tuple of (model, params, train_accuracy, validation_accuracy)\n","# Compare and return best model\n","def compareBestModel(best_model, new_model):\n","\n","    if (best_model is None) or (best_model[3] < new_model[3]):\n","        return new_model\n","    else:\n","        return best_model\n","\n","# Dump best model\n","def saveBestModel(path, file_prefix, best_model):\n","    \n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","    \n","    file = file_prefix + \"-train-acc-\" + str(round(best_model[2], 10)) + \"-val-acc-\" + str(round(best_model[3], 10)) + \".joblib\"\n","    dump(best_model, os.path.join(path, file)) \n","\n","# Load best model\n","def loadBestModel(path, file):\n","    return load(os.path.join(path, file))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPPr1HO3Hz7F","colab_type":"code","colab":{}},"source":["# Save a log for each experiment execution (params for each execution)\n","def saveExecutionLog(path, file_prefix, data, columns):\n","    save = pd.DataFrame(columns=columns, data=data)\n","    save.to_csv(os.path.join(path, file_prefix + \"-execution-log.csv\"), index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fDX3lT1mHz7L","colab_type":"text"},"source":["<h5>Parameter Variations</h5>"]},{"cell_type":"code","metadata":{"id":"rOo5T0PaHz7M","colab_type":"code","colab":{}},"source":["experiment_by_dataset = [\n","    { \"train\": [\"pvs_1\", \"pvs_3\", \"pvs_4\", \"pvs_6\", \"pvs_7\", \"pvs_9\"], \"test\":  [\"pvs_2\", \"pvs_5\", \"pvs_8\"]},\n","    { \"train\": [\"pvs_1\", \"pvs_2\", \"pvs_3\", \"pvs_7\", \"pvs_8\", \"pvs_9\"], \"test\":  [\"pvs_4\", \"pvs_5\", \"pvs_6\"]},\n","    { \"train\": [\"pvs_1\", \"pvs_2\", \"pvs_4\", \"pvs_6\", \"pvs_8\", \"pvs_9\"], \"test\":  [\"pvs_3\", \"pvs_5\", \"pvs_7\"]}\n","]\n","\n","experiment_by_fields = [\n","    getFields(acc=True,  gyro=False, speed=True, below_suspension=True), # acc_below_suspension\n","    getFields(acc=False, gyro=True,  speed=True, below_suspension=True), # gyro_below_suspension\n","    getFields(acc=True,  gyro=True,  speed=True, below_suspension=True), # acc_gyro_below_suspension\n","    getFields(acc=True,  gyro=False, speed=True, above_suspension=True), # acc_above_suspension\n","    getFields(acc=False, gyro=True,  speed=True, above_suspension=True), # gyro_above_suspension\n","    getFields(acc=True,  gyro=True,  speed=True, above_suspension=True), # acc_gyro_above_suspension\n","    getFields(acc=True,  gyro=False, speed=True, dashboard=True), # acc_dashboard\n","    getFields(acc=False, gyro=True,  speed=True, dashboard=True), # gyro_dashboard\n","    getFields(acc=True,  gyro=True,  speed=True, dashboard=True) # acc_gyro_dashboard\n","]\n","\n","experiment_by_window_fn = [\n","    extractFeatureFixedWindow, # fixed\n","    extractFeatureMovingWindow # moving\n","]\n","\n","experiment_by_agg_fn = [\n","    { \"acc\": [\"mean\"],               \"gyro\": [\"mean\"],               \"speed\": [\"mean\"] },\n","    { \"acc\": [\"std\"],                \"gyro\": [\"std\"],                \"speed\": [\"mean\"] },\n","    { \"acc\": [\"var\"],                \"gyro\": [\"var\"],                \"speed\": [\"mean\"] },\n","    { \"acc\": [\"mean\", \"std\"],        \"gyro\": [\"mean\", \"std\"],        \"speed\": [\"mean\"] },\n","    { \"acc\": [\"mean\", \"var\"],        \"gyro\": [\"mean\", \"var\"],        \"speed\": [\"mean\"] },\n","    { \"acc\": [\"mean\", \"std\", \"var\"], \"gyro\": [\"mean\", \"std\", \"var\"], \"speed\": [\"mean\"] }\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W259yei2Hz7Q","colab_type":"text"},"source":["<h5>Labels Fields</h5>"]},{"cell_type":"code","metadata":{"id":"BO-LtLikHz7R","colab_type":"code","colab":{}},"source":["surface_type_labels = [\"land\", \"cobblestone\", \"asphalt\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-SQ-S4e7TktX","colab_type":"code","colab":{}},"source":["surface_type_labels_plot = [\"Dirt \\n Road\", \"Cobblestone \\n Road\", \"Asphalt \\n Road\"]  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j8t4Ei3sHz7Y","colab_type":"text"},"source":["<h5> Util Functions </h5>"]},{"cell_type":"code","metadata":{"id":"5pkfSTwFHz7i","colab_type":"code","colab":{}},"source":["def createPathIfNotExists(path):\n","\n","    if not os.path.exists(path):\n","        os.makedirs(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"74s9lKv5Hz7e","colab_type":"code","colab":{}},"source":["def plot(data, labels, gyro_field=None, acc_field=None, speed_field=None):\n","    \n","    plt.figure(figsize=(16,6)) \n","    \n","    if(speed_field):\n","        (data[speed_field] * 3.6).plot()\n","    \n","    if(gyro_field):\n","        data[gyro_field].plot(color=\"g\")\n","    \n","    if(acc_field):\n","        data[acc_field].plot(color=\"y\")\n","\n","    i = 1\n","    \n","    for col in labels.columns:\n","        (labels[col] * i * 20).plot(linewidth=2)\n","        i += 1\n","\n","    plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTqIDvfnU89N","colab_type":"code","colab":{}},"source":["def plotConfusionMatrix(values, title, labels=surface_type_labels_plot, figsize=(4, 4)):\n","    con_mat_df = pd.DataFrame(values, index=labels, columns=labels)\n","    figure = plt.figure(figsize=figsize)\n","    sns.set(font_scale=1.2)\n","    sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues, annot_kws={\"size\": 14})\n","    plt.tight_layout()\n","    plt.title(title)\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.show()\n","    figure.savefig('confusion_matrix.png', bbox_inches=\"tight\")\n","    # plt.savefig('results.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_fqt8HdCVlQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}